## 综述

可视化是研究机器学习可解释性领域下的分支————深度学习可解释性的一类方法。方法围绕深度学习模型，提取网络中的参数，用算法做可视化分析，解释模型为什么会产生这样的结果。

### 学习路线
#### 入门：
[Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)  
写的非常好的一本书，通俗易懂+代码+数据，手把手带你入门机器学习的解释性，深入浅出去理解和解释晦涩难懂的机器学习模型。

[AI Explainability Whitepaper](https://github.com/iluccica/Secret/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%8F%AF%E8%A7%86%E5%8C%96/%E7%BB%BC%E8%BF%B0/AI%20Explainability%20Whitepaper.pdf) 谷歌2019发布的人工智能可解释性白皮书。

### 子方向
#### 类激活映射（CAM）

#### 基于输入图像扰动（Perturbation Based）
#### 自身可解释的深度学习模型
基本是深度学习可解释性大佬————张拳石老师实验室的成果，务必关注他的知乎号~
#### 其他杂七杂八

其他方向还有Sliency Map、Guided-Backpropagation等等杂七杂八的早期方法，在 Perturbation Based/IGOS 的“Related Work”中有很棒的整理

老学姐的知乎收藏：https://www.zhihu.com/collection/485625078

老学姐的论文笔记和学习笔记：https://blog.csdn.net/qq_34813925

## 工具类

[Techniques for Interpretable Machine Learning](https://github.com/iluccica/Secret/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%8F%AF%E8%A7%86%E5%8C%96/Techniques%20for%20interpretable%20machine%20learing.pdf)

## 大佬
知乎：张拳石

神仙小姐姐的github：https://github.com/oneTaken/awesome_deep_learning_interpretability



